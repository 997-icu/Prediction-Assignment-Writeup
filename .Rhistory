install.packages("lmtest")
library(lmtest)
lmtest(fit3)
lrtest(fit3)
?lrtest
lrtest(fit1,fit3)
4.fit4 <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit4 <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fit4)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit5 <- lm(y~x)
hatvalues(fit5)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit6 <- lm(y~x)
dfbeta(fit6)
hatvalues(fit6)
?dfbeta
library(MASS)
data("shuttle")
force(shuttle)
View(shuttle)
View(shuttle)
library(tidyverse)
View(shuttle)
shuttle <- mutate(shuttle,use2 = ifelse(use == "auto",1,0))
View(shuttle)
fit1 <-glm(use2~wind,data = shuttle,family = "binomial")
summary(fit1)
View(shuttle)
View(shuttle)
fit1$fitted.values
fit1$y
fit1$rank
unique(fit1$fitted.values)
0.5625/(1-0.5625)
0.5625/(1-0.5625)  /(0.5703125/(1-0.5703125))
View(shuttle)
fit2 <‐ glm(use2 ~ wind + magn, data = shuttle, family ="binomial")
fit2 <- glm(use2 ~ wind + magn, data = shuttle, family ="binomial")
summary(fit2)
log(0.969)
unique(fit2$fitted.values)
(0.5898897)/(1-0.5898897) /(0.5976103/(1-0.5976103))
uniqeu(shuttle$wind)
unique(shuttle$wind)
fit3 <-glm(use2~I(1-wind),data = shuttle,family = "binomial")
fit3 <-glm(use2~(1-wind),data = shuttle,family = "binomial")
summary(fit3)
fit3 <-glm(use2~(1- factor(wind)),data = shuttle,family = "binomial")
summary(fit3)
View(shuttle)
shuttle <- mutate(shuttle,wind2 = ifelse(wind == "head",1,0))
fit3 <-glm(use2~(1- wind2),data = shuttle,family = "binomial")
summary(fit3)
fit3 <-glm(use2~I(1- wind2),data = shuttle,family = "binomial")
summary(fit3)
fit1 <-glm(use2~wind,data = shuttle,family = "binomial")
summary(fit1)
fit1 <-glm(use2~wind2,data = shuttle,family = "binomial")
summary(fit1)
data("InsectSprays")
force(InsectSprays)
View(InsectSprays)
fit4 <- glm(count~factor(spray),data = InsectSprays,family = "poisson")
summary(fit4)
View(InsectSprays)
?glm
anova(fit4)
fit4$coefficients
fit4 <- glm(count~spray,data = InsectSprays,family = "poisson")
summary(fit4)
fit4 <- glm(count~relevel(spray),data = InsectSprays,family = "poisson")
?relevel
View(InsectSprays)
library(datasets)
data("InsectSprays")
-0.6 *25/66 +0.6 *17 /66 +0.2 *4/11
0.2 *25/66 -y *17/66 +0.5 *4/11
0.2 *25/66 -1 *17/66 +0.5 *4/11
0.4 *42/66 -0.7 *4/11
P <- matrix(0.2,0.4,0.4,0.1,0.5,0.4,0.6,0.3,0.1,nrow = 3,ncol = 3)
P <- matrix(c(0.2,0.4,0.4,0.1,0.5,0.4,0.6,0.3,0.1),nrow = 3,ncol = 3)
p
P
a <- t(P)
a
eigen(a)
k <- diag(c(1,2,3),nrow = 3,ncol = 3)
k
solve(k)
a
eigen(a)
b <- eigen(a)$vectors
b
b %*% diag(c(1,0,0),nrow = 3,ncol = 3) %*% solve(b)
?solbe
?solve
-0.8 *0.282 +0.1 *0.410 +0.6 *0.308
P = matrix(c(0.75,0.25,0,0,0,0,0,))
P <- matrix(c(0.75,0.25,0,0,0,0,0,
0.5,0.25,0.25,0,0,0,0,
0.25,0.25,0.25,0.25,0,0,0,
0.25,0,0,0.25,0.25,0.25,0,
0.25,0,0,0,0.25,0.25,0.25,
0.25,0,0,0,0,0.25,0.5
)nrow = 7,ncol = 7)
P <- matrix(c(0.75,0.25,0,0,0,0,0,
0.5,0.25,0.25,0,0,0,0,
0.25,0.25,0.25,0.25,0,0,0,
0.25,0,0,0.25,0.25,0.25,0,
0.25,0,0,0,0.25,0.25,0.25,
0.25,0,0,0,0,0.25,0.5
),nrow = 7,ncol = 7)
P
P <- t(P)
P
P <- matrix(c(0.75,0.25,0,0,0,0,0,
0.5,0.25,0.25,0,0,0,0,
0.25,0.25,0.25,0.25,0,0,0,
0.25,0,0.25,0.25,0.25,0,0,
0.25,0,0,0.25,0.25,0.25,0,
0.25,0,0,0,0.25,0.25,0.25,
0.25,0,0,0,0,0.25,0.5
),nrow = 7,ncol = 7)
P <- t(P)
P
eigen(P)
eigen(P)$vectors %*% diag(c(1,0,0,0,0,0,0)) %*% solve(eigen(P)$vectors)
?mtcars
knitr::opts_chunk$set(echo = TRUE)
t.test(data = mtcars,mpg~am)$p.value
t.test(data = mtcars,mpg~am)$p.value  #P value <0.05
t.test(data = mtcars,mpg~am)$estimate
print(t.test(data = mtcars,mpg~am)$p.value)  #P value <0.05
#Clearly there are some differences in mean value of different transmission types
print(t.test(data = mtcars,mpg~am)$estimate)
print("P value: ",t.test(data = mtcars,mpg~am)$p.value)  #P value <0.05
print(c("P value: ",t.test(data = mtcars,mpg~am)$p.value))  #P value <0.05
#Clearly there are some differences in mean value of different transmission types
print(t.test(data = mtcars,mpg~am)$estimate)
print(c("P value: ",t.test(data = mtcars,mpg~am)$p.value))  #P value <0.05
#Clearly there are some differences in mean value of different transmission types
print(t.test(data = mtcars,mpg~am)$estimate)
24.39231-17.14737
plot(data = mtcars ,mpg ~am)
library(tidyverse)
mtcars %>% group_by(am) %>% mean(mpg)
class(mtcars$mpg)
mtcars
fit <- lm(mpg~., data = mtcars) #including all variables
summary(fit)
fit$coefficients
summary(fit)$coeff
summary(fit)
back_selection <- step(fit)
summary(back_selection)
fit <- lm(mpg~., data = mtcars) #including all variables
summary(fit)   #R square is 0.869,which indicates our model is pretty good.
#But all variables have P-value more than 0.05,so we can't conclude which variables are more signigicant.
fit <- lm(mpg~., data = mtcars) #including all variables
summary(fit)   #R square is 0.869,which indicates our model is pretty good.
fit <- lm(mpg~., data = mtcars) #including all variables
summary(fit)   #R square is 0.869,which indicates our model is pretty good.
fit <- lm(mpg~., data = mtcars) #including all variables
summary(fit)   #R square is 0.869,which indicates our model is pretty good.
#But all variables have P-value more than 0.05
#so we can't conclude which variables are more signigicant.
#****************results are hide ***************
#use backward selection to select the best model
back_selection <- step(fit)
summary(back_selection)
?step
#****************results are hide ***************
#use backward selection to select the best model
back_selection <- step(fit,direction = "backward",trace = FALSE)
summary(back_selection)
library(ggplot2); library(dplyr) ;library(ggpubr) #Load the packages we need
data("mtcars")       #Load the mtcars dataset
# Let x be geom_point(), y be geom_smooth(formula = y~x,method = "lm")
x<- geom_point() ; y<- geom_smooth(formula = y~x,method = "lm")
p1 <- ggplot(mtcars,aes(x = cyl ,y=mpg)) +x+y;p2 <- ggplot(mtcars,aes(x = disp ,y=mpg))+x+y
p3 <- ggplot(mtcars,aes(x = hp ,y=mpg)) +x+y;p4 <- ggplot(mtcars,aes(x = drat ,y=mpg))+x+y
p5 <- ggplot(mtcars,aes(x = wt ,y=mpg)) +x+y;p6 <- ggplot(mtcars,aes(x = qsec ,y=mpg))+x+y
p7 <- ggplot(mtcars,aes(x = vs ,y=mpg)) +x+y;p8 <- ggplot(mtcars,aes(x = am ,y=mpg))+x+y
p9<-ggplot(mtcars,aes(x = gear ,y=mpg)) +x+y;p10<-ggplot(mtcars,aes(x = carb ,y=mpg))+x+y
ggpubr::ggarrange(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,nrow = 2,ncol = 5)
mtcars$gear <- as.factor(mtcars$gear)   #Change the categorical variables to factor for later analysis
mtcars$cyl <- as.factor(mtcars$cyl);mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- as.factor(mtcars$am); mtcars$carb <- as.factor(mtcars$carb)
#P value <0.05, so we reject the null hypothesis of no difference between transmission types
print(c("P value: ",t.test(data = mtcars,mpg~am)$p.value))
#The difference in mean value of MPG between automatic and manual transmissions is 7.24494
print(t.test(data = mtcars,mpg~am)$estimate)
24.39231 - 17.14737
#***************results are hide *********************8
fit <- lm(mpg~., data = mtcars) #including all variables
summary(fit)   #R square is 0.869,which indicates our model is pretty good.
#But all variables have P-value more than 0.05
#so we can't conclude which variables are more signigicant.
#****************results are hide ***************
#use backward selection to select the best model
back_selection <- step(fit,direction = "backward",trace = FALSE)
summary(back_selection)
back_selection$coefficients
plot(back_selection)
par(mfrow = c(1,4))
plot(back_selection)
par(mfrow = c(1,4))
plot(back_selection)    #Make a residual plot
dfbeta(back_selection)
sum(abs(dfbetas(back_selection)))>1)
sum((abs(dfbetas(back_selection)))>1)
par(mfrow = c(1,4))
plot(back_selection)    #Make a residual plot
?mtcars
install.packages("shiny")
BiocManager::install("rCharts")
BiocManager::install("rCharts")
BiocManager::install("rCharts")
install.packages("rCharts",repos='https://mran.microsoft.com/snapshot/2019-02-01/')
install.packages("manipulate",repos='https://mran.microsoft.com/snapshot/2019-02-01/')
install.packages("googleVis",repos='https://mran.microsoft.com/snapshot/2019-02-01/')
setwd("D:/Coursera/Specialization/Data Science Specialization/Data Science：Statistics and Machine Learning Specialization/Pratical Machine Learning/week4/Prediction Assignment Writeup")
knitr::opts_chunk$set(echo = TRUE)
#Load the packages we need
library(tidyverse)   #Including ggplot2 and dplyr
library(ggpubr)
library(caret)   #Machine Learning Package
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.path = "figures/")
?caret
??caret
#The working directory has already been set
#Load the data
train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")
View(train)
#The working directory has already been set
#Load the data
train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")
print(dim(train))
print(dim(test))
#The working directory has already been set
#Load the data
train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")
print(dim(train))
print(dim(test))
print(head(train))
#The working directory has already been set
#Load the data
train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")
#See the dimention of our dataset
print(dim(train))
print(dim(test))
#A brief overview of dataset
head(train)
#A brief overview of dataset
print(head(train))
View(train)
colnames(train)
#A brief overview of class(outcome)
print(unique(train$classe))
#The working directory has already been set
#Load the data
train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")
#See the dimention of our dataset
print(dim(train))
print(dim(test))
#A brief overview of class(outcome)
print(unique(train$classe))
View(train)
?read.csv
#The working directory has already been set
#Load the data
train <- read.csv("pml-training.csv",na.strings = c("","NA"))
test <- read.csv("pml-testing.csv",na.strings = c("","NA"))
#See the dimention of our dataset
print(dim(train))
print(dim(test))
#A brief overview of class(outcome)
print(unique(train$classe))
View(train)
View(test)
View(train)
#The working directory has already been set
#Load the data
train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")
#See the dimention of our dataset
print(dim(train))
print(dim(test))
#A brief overview of class(outcome)
print(unique(train$classe))
View(train)
View(train)
View(train)
View(train)
is.na(train[train$new_window == "yes"])
is.na(train[train$new_window == "yes",])
sum(is.na(train[train$new_window == "yes",]))
View(train)
View(test)
print(nrow(train[train$new_window == "yes",]))
print(sum(is.na(train[train$new_window == "yes",])))
print(sum(is.na(train)))
print(nrow(train[train$new_window == "yes",]))
print(sum(is.na(train[train$new_window == "yes",])))
print(nrow(is.na(train)))
print(nrow(train[train$new_window == "yes",]))
print(sum(is.na(train[train$new_window == "yes",])))
print(nrow(train[train$new_window == "yes",]))
print(sum(is.na(train[train$new_window == "yes",])))
new_train <- train %>% filter(new_window == "no")
dim(new_train)
View(new_train)
View(train)
#Delete those NA columns as well
new_train <- train %>% filter(new_window == "no")
new_train <- new_train[,-which(apply(new_train,2,function(x) all(is.na(x))))]
dim(new_train)
View(new_train)
View(train)
View(new_train)
#Delete those NA columns and blank columns as well
new_train <- train %>% filter(new_window == "no")
#Delete NA columns
new_train <- new_train[,-which(apply(new_train,2,function(x) all(is.na(x))))]
#Delete blank columns
new_train <- new_train[,-which(apply(new_train,2,function(x) all(x=="")))]
dim(new_train)
View(new_train)
View(new_train)
#Delete those NA columns and blank columns as well
new_train <- train %>% filter(new_window == "no")
#Delete NA columns
new_train <- new_train[,-which(apply(new_train,2,function(x) all(is.na(x))))]
#Delete blank columns
new_train <- new_train[,-which(apply(new_train,2,function(x) all(x=="")))]
print(dim(new_train))
print(is.na(new_train))
#Delete those NA columns and blank columns as well
new_train <- train %>% filter(new_window == "no")
#Delete NA columns
new_train <- new_train[,-which(apply(new_train,2,function(x) all(is.na(x))))]
#Delete blank columns
new_train <- new_train[,-which(apply(new_train,2,function(x) all(x=="")))]
print(dim(new_train))
print(sum(is.na(new_train)))
View(train)
View(new_train)
View(test)
colnames(new_train)
#Delete those NA columns and blank columns as well
new_train <- train %>% filter(new_window == "no")
#Delete NA columns
new_train <- new_train[,-which(apply(new_train,2,function(x) all(is.na(x))))]
#Delete blank columns
new_train <- new_train[,-which(apply(new_train,2,function(x) all(x=="")))]
#Select those features in test set,too
new_test <- test %>% select(colnames(new_train))
View(test)
View(train)
intersect(colnames(train),colnames(test))
sum(intersect(colnames(train),colnames(test)))
length(intersect(colnames(train),colnames(test)))
length(setdiff(colnames(train),colnames(test)))
(setdiff(colnames(train),colnames(test)))
(setdiff(colnames(test),colnames(train)))
test$problem_id
View(test)
#sum of the intersection of column names between original train set and test set
print(sum(intersect(colnames(train),colnames(test))))
#sum of the intersection of column names between original train set and test set
print(length(intersect(colnames(train),colnames(test))))
#sum of the intersection of column names between original train set and test set
print(length(intersect(colnames(train),colnames(test))))   #159
#find the difference between them
print(setdiff(colnames(train),colnames(test)))
print(setdiff(colnames(test),colnames(train)))
#Select intersection
new_test <- test %>% select(intersect(colnames(train),colnames(test)))
#Delete NA columns
new_test <- new_test[,-which(apply(new_train,2,function(x) all(is.na(x))))]
#Delete blank columns
new_test <- new_test[,-which(apply(new_train,2,function(x) all(x=="")))]
View(new_test)
#Select intersection
new_test <- test %>% select(intersect(colnames(train),colnames(test)))
#Delete NA columns
#new_test <- new_test[,-which(apply(new_train,2,function(x) all(is.na(x))))]
#Delete blank columns
#new_test <- new_test[,-which(apply(new_train,2,function(x) all(x=="")))]
#Select intersection
new_test <- test %>% select(intersect(colnames(train),colnames(test)))
#Delete NA columns
new_test <- new_test[,-which(apply(new_test,2,function(x) all(is.na(x))))]
#Delete blank columns
new_test <- new_test[,-which(apply(new_test,2,function(x) all(x=="")))]
#Select intersection
new_test <- test %>% select(intersect(colnames(train),colnames(test)))
#Delete NA columns
new_test <- new_test[,-which(apply(new_test,2,function(x) all(is.na(x))))]
#Delete blank columns
new_test <- new_test[,-which(apply(new_test,2,function(x) all(x=="")))]
#Select intersection
new_test <- test %>% select(intersect(colnames(train),colnames(test)))
#Delete NA columns
new_test <- new_test[,-which(apply(new_test,2,function(x) all(is.na(x))))]
#Delete blank columns
#new_test <- new_test[,-which(apply(new_test,2,function(x) all(x=="")))]
View(new_test)
#Select intersection
new_test <- test %>% select(intersect(colnames(train),colnames(test)))
#Delete NA columns
new_test <- new_test[,-which(apply(new_test,2,function(x) all(is.na(x))))]
#Intersect again to check
print(length(intersect(colnames(new_train),colnames(new_test))))
#See the new dim of new_train
print(dim(new_train))
#See if there are still some NAs
print(sum(is.na(new_train)))
#See the new dim fo new_test
print(dim(new_test))
#See if there are NAs in new_test
print(sum(is.na(new_test))
#Intersect again to check
print(length(intersect(colnames(new_train),colnames(new_test))))
#See the new dim of new_train
print(dim(new_train))
#See if there are still some NAs
print(sum(is.na(new_train)))
#See the new dim fo new_test
print(dim(new_test))
#See if there are NAs in new_test
print(sum(is.na(new_test)))
#Intersect again to check
print(length(intersect(colnames(new_train),colnames(new_test))))
?trainControl
?train
install.packages("ranger")
install.packages("ordinalForest")
#Load the packages we need
library(tidyverse)   #Including ggplot2 and dplyr
library(ggpubr)
library(caret)   #Machine Learning Package
library(e1071)
library(ranger)
library(ordinalForest)
library(randomForest)
install.packages("gbm")
#Load the packages we need
library(tidyverse)   #Including ggplot2 and dplyr
library(ggpubr)
library(caret)   #Machine Learning Package
library(e1071)
library(ranger)
library(ordinalForest)
library(randomForest)
library(gbm)
library(plyr)
set.seed(123456)
#Set the train control
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,returnResamp = "all")
#Hyperparameter search grid
gbmGrid <- expand.grid(.interaction.depth = c(1, 3),
.n.trees = c(50, 100, 150, 200, 250, 300),
.shrinkage = 0.1,.n.minobsinnode = 10)
gbmFit <- train(classe~.,data = new_train,
method = "gbm",trControl = fitControl,tuneGrid = gbmGrid,verbose = FALSE)
set.seed(123456)
#Set the train control,random search the hyperparameters
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
classProbs = FALSE,
summaryFunction = twoClassSummary,
search = "random")
rf_fit <- train(classe~.,data = new_train,method = "rf",metric = "ROC",trControl = fitControl)
set.seed(123456)
#Set the train control,random search the hyperparameters
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary,
search = "random")
rf_fit <- train(classe~.,data = new_train,method = "rf",metric = "ROC",trControl = fitControl)
set.seed(123456)
#Set the train control,random search the hyperparameters
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
classProbs = TRUE,
search = "random")
rf_fit <- train(classe~.,data = new_train,method = "rf",metric = "ROC",trControl = fitControl)
?train
set.seed(123456)
#Set the train control,random search the hyperparameters
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
classProbs = TRUE,
search = "random")
rf_fit <- train(classe~.,data = new_train,method = "rf",metric = "Accuracy",trControl = fitControl,prox = TRUE)
install.packages("parallel")
install.packages("doParallel")
